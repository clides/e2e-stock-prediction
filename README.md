# End-to-End Stock Prediction using LSTMs

This project implements an end-to-end machine learning pipeline to predict stock prices using a Long Short-Term Memory (LSTM) model. The pipeline is built with a modular approach, allowing for easy configuration and execution of different stages, from data ingestion to model evaluation.

## Project Structure

The project is organized as follows:

-   `src/lstmPredictor/`: Contains the core source code for the project.
    -   `components/`: Individual components for each pipeline stage.
    -   `config/`: Configuration management.
    -   `constants/`: Project-specific constants.
    -   `entity/`: Data entity definitions.
    -   `pipeline/`: Defines the stages of the ML pipeline.
    -   `utils/`: Utility functions.
-   `main.py`: Main script to run the entire ML pipeline.
-   `params.yaml`: Contains all the parameters for the different stages of the pipeline.
-   `config/config.yaml`: Main configuration file for the project.
-   `dvc.yaml`: DVC pipeline definition file.
-   `requirements.txt`: Project dependencies.
-   `setup.py`: Project setup script.
-   `research/`: Jupyter notebooks for research and experimentation.
-   `artifacts/`: Stores data, models, and other artifacts generated by the pipeline.

## Getting Started

### Prerequisites

-   Python 3.8 or later
-   Git

### Installation

1.  **Clone the repository:**

    ```bash
    git clone https://github.com/clides/e2e-stock-prediction.git
    cd e2e-stock-prediction
    ```

2.  **Create a virtual environment (optional but recommended):**

    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install the required dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

## Usage

### Running the Pipeline

To run the entire end-to-end pipeline, execute the `main.py` script:

```bash
python main.py
```

This will run all the stages of the pipeline in sequence, from data ingestion to model evaluation.
(TODO: Final stage includes model inference to predict stock price tomorrow)

### Pipeline Stages

The pipeline consists of the following stages, which are executed in order by `main.py`:

1.  **Data Ingestion:** Fetches historical stock data.
2.  **Prepare Base Model:** Initializes the LSTM model with pre-defined architecture.
3.  **Data Preprocessing:** Preprocesses the raw data into a suitable format for training.
4.  **Model Training:** Trains the LSTM model on the preprocessed data.
5.  **Model Evaluation:** Evaluates the trained model on the test set and logs the metrics.
(TODO: Final stage includes model inference to predict stock price tomorrow)

### Configuration

The behavior of the pipeline can be customized by modifying the `params.yaml` file. This file contains parameters for each stage of the pipeline, such as:

-   **`data_ingestion`**: Ticker symbol, number of days of data to fetch (how many days to train on).
-   **`base_model`**: LSTM model architecture (input size, hidden size, number of layers, etc.).
-   **`data_preprocessing`**: Sequence length, train/test/validation split sizes, features to use.
-   **`training`**: Learning rate, number of epochs, optimizer, etc.
-   **`evaluation`**: Metrics to calculate.

To change a parameter, simply edit the corresponding value in `params.yaml` and re-run the pipeline.
